{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6Pj_dFZKqrU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['bear', 'set', 'square', 'lead', 'criteria']"
      ],
      "metadata": {
        "id": "xoDKYdLaMJQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "synonyms = {}\n",
        "for word in words:\n",
        "    synonyms[word] = set()\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms[word].add(lemma.name())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fzDtz6LMsoY",
        "outputId": "131a3cf8-766b-429b-8128-965d36cd22f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMByByCpMvd4",
        "outputId": "a522e935-8742-4b14-beb1-3690f3a84733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bear': {'abide',\n",
              "  'accept',\n",
              "  'acquit',\n",
              "  'assume',\n",
              "  'bear',\n",
              "  'behave',\n",
              "  'birth',\n",
              "  'brook',\n",
              "  'carry',\n",
              "  'comport',\n",
              "  'conduct',\n",
              "  'contain',\n",
              "  'deliver',\n",
              "  'deport',\n",
              "  'digest',\n",
              "  'endure',\n",
              "  'expect',\n",
              "  'gestate',\n",
              "  'give_birth',\n",
              "  'have',\n",
              "  'have_a_bun_in_the_oven',\n",
              "  'hold',\n",
              "  'pay',\n",
              "  'put_up',\n",
              "  'stand',\n",
              "  'stick_out',\n",
              "  'stomach',\n",
              "  'suffer',\n",
              "  'support',\n",
              "  'take_over',\n",
              "  'tolerate',\n",
              "  'turn_out',\n",
              "  'wear',\n",
              "  'yield'},\n",
              " 'set': {'Set',\n",
              "  'Seth',\n",
              "  'adjust',\n",
              "  'arrange',\n",
              "  'band',\n",
              "  'bent',\n",
              "  'circle',\n",
              "  'coif',\n",
              "  'coiffe',\n",
              "  'coiffure',\n",
              "  'congeal',\n",
              "  'correct',\n",
              "  'countersink',\n",
              "  'curing',\n",
              "  'define',\n",
              "  'determine',\n",
              "  'determined',\n",
              "  'dictated',\n",
              "  'do',\n",
              "  'dress',\n",
              "  'exercise_set',\n",
              "  'fit',\n",
              "  'fix',\n",
              "  'fixed',\n",
              "  'fructify',\n",
              "  'gear_up',\n",
              "  'go_down',\n",
              "  'go_under',\n",
              "  'hardened',\n",
              "  'hardening',\n",
              "  'jell',\n",
              "  'laid',\n",
              "  'lay',\n",
              "  'lay_out',\n",
              "  'limit',\n",
              "  'localise',\n",
              "  'localize',\n",
              "  'located',\n",
              "  'lot',\n",
              "  'mark',\n",
              "  'place',\n",
              "  'placed',\n",
              "  'plant',\n",
              "  'pose',\n",
              "  'position',\n",
              "  'prepare',\n",
              "  'primed',\n",
              "  'put',\n",
              "  'readiness',\n",
              "  'ready',\n",
              "  'rig',\n",
              "  'rigid',\n",
              "  'set',\n",
              "  'set_up',\n",
              "  'sic',\n",
              "  'situated',\n",
              "  'solidification',\n",
              "  'solidifying',\n",
              "  'specify',\n",
              "  'stage_set',\n",
              "  'typeset'},\n",
              " 'square': {'feather',\n",
              "  'foursquare',\n",
              "  'hearty',\n",
              "  'lame',\n",
              "  'public_square',\n",
              "  'satisfying',\n",
              "  'second_power',\n",
              "  'solid',\n",
              "  'square',\n",
              "  'square_toes',\n",
              "  'square_up',\n",
              "  'squarely',\n",
              "  'straight',\n",
              "  'straightforward',\n",
              "  'substantial'},\n",
              " 'lead': {'Pb',\n",
              "  'atomic_number_82',\n",
              "  'booster_cable',\n",
              "  'chair',\n",
              "  'conduce',\n",
              "  'conduct',\n",
              "  'confidential_information',\n",
              "  'contribute',\n",
              "  'direct',\n",
              "  'extend',\n",
              "  'go',\n",
              "  'guide',\n",
              "  'head',\n",
              "  'hint',\n",
              "  'jumper_cable',\n",
              "  'jumper_lead',\n",
              "  'lead',\n",
              "  'lead-in',\n",
              "  'lead_story',\n",
              "  'leading',\n",
              "  'leash',\n",
              "  'leave',\n",
              "  'lede',\n",
              "  'moderate',\n",
              "  'pass',\n",
              "  'pencil_lead',\n",
              "  'precede',\n",
              "  'principal',\n",
              "  'result',\n",
              "  'run',\n",
              "  'spark_advance',\n",
              "  'star',\n",
              "  'steer',\n",
              "  'take',\n",
              "  'tether',\n",
              "  'tip',\n",
              "  'top',\n",
              "  'track',\n",
              "  'trail',\n",
              "  'wind'},\n",
              " 'criteria': {'criterion', 'measure', 'standard', 'touchstone'}}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "meanings = {}\n",
        "for word in words:\n",
        "    synsets = wordnet.synsets(word)\n",
        "\n",
        "    if len(synsets) >= 3:\n",
        "        third_meaning = synsets[2]\n",
        "        meanings[word] = third_meaning.definition()\n",
        "\n",
        "for word, meaning in meanings.items():\n",
        "    print(f\"3rd meaning for {word}: {meaning}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJxlhAu5Nc2r",
        "outputId": "8d8022bf-3392-49c8-d234-61f09d1fe09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3rd meaning for bear: have\n",
            "3rd meaning for set: several exercises intended to be done in series\n",
            "3rd meaning for square: an open area at the meeting of two or more streets\n",
            "3rd meaning for lead: evidence pointing to a possible solution\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "nouns = {}\n",
        "for word in words:\n",
        "    synsets = wordnet.synsets(word)\n",
        "    noun_synsets = [syn for syn in synsets if syn.pos() == 'n']\n",
        "\n",
        "    if noun_synsets:\n",
        "        noun_words = [lemma.name() for syn in noun_synsets for lemma in syn.lemmas()]\n",
        "        nouns[word] = noun_words\n",
        "\n",
        "for word, word_nouns in nouns.items():\n",
        "    print(f\"Nouns for {word}: {word_nouns}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "taxAb1DUX9l9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25735f57-872f-465c-e79a-9602f42048f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nouns for bear: ['bear', 'bear']\n",
            "Nouns for set: ['set', 'set', 'set', 'exercise_set', 'stage_set', 'set', 'set', 'circle', 'band', 'lot', 'bent', 'set', 'set', 'set', 'hardening', 'solidifying', 'solidification', 'set', 'curing', 'Set', 'Seth', 'set', 'set', 'readiness', 'set']\n",
            "Nouns for square: ['square', 'foursquare', 'square', 'second_power', 'public_square', 'square', 'square', 'square', 'lame', 'square', 'square_toes', 'square', 'square']\n",
            "Nouns for lead: ['lead', 'lead', 'Pb', 'atomic_number_82', 'lead', 'track', 'trail', 'lead', 'lead', 'lead', 'lead-in', 'lede', 'lead', 'star', 'principal', 'lead', 'lead', 'tip', 'lead', 'steer', 'confidential_information', 'wind', 'hint', 'lead', 'lead_story', 'spark_advance', 'lead', 'leash', 'tether', 'lead', 'lead', 'leading', 'lead', 'pencil_lead', 'jumper_cable', 'jumper_lead', 'lead', 'booster_cable', 'lead']\n",
            "Nouns for criteria: ['standard', 'criterion', 'measure', 'touchstone', 'criterion', 'standard']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verbs = {}\n",
        "for word in words:\n",
        "    synsets = wordnet.synsets(word)\n",
        "    verb_synsets = [syn for syn in synsets if syn.pos() == 'v']  # Filter only verb synsets\n",
        "\n",
        "    if verb_synsets:\n",
        "        verb_words = [lemma.name() for syn in verb_synsets for lemma in syn.lemmas()]\n",
        "        verbs[word] = verb_words\n",
        "\n",
        "# Print the verbs for each word\n",
        "for word, word_verbs in verbs.items():\n",
        "    print(f\"Verbs for {word}: {word_verbs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DV5xVYbbiUc",
        "outputId": "a3a54f76-de7d-4963-c054-e0abe2a13867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verbs for bear: ['bear', 'give_birth', 'deliver', 'bear', 'birth', 'have', 'digest', 'endure', 'stick_out', 'stomach', 'bear', 'stand', 'tolerate', 'support', 'brook', 'abide', 'suffer', 'put_up', 'bear', 'bear', 'turn_out', 'bear', 'take_over', 'accept', 'assume', 'hold', 'bear', 'carry', 'contain', 'yield', 'pay', 'bear', 'wear', 'bear', 'behave', 'acquit', 'bear', 'deport', 'conduct', 'comport', 'carry', 'bear', 'hold', 'hold', 'carry', 'bear', 'have_a_bun_in_the_oven', 'bear', 'carry', 'gestate', 'expect']\n",
            "Verbs for set: ['put', 'set', 'place', 'pose', 'position', 'lay', 'determine', 'set', 'specify', 'set', 'determine', 'define', 'fix', 'limit', 'set', 'mark', 'set', 'set', 'fix', 'prepare', 'set_up', 'ready', 'gear_up', 'set', 'set', 'set', 'localize', 'localise', 'place', 'set', 'go_down', 'go_under', 'arrange', 'set', 'plant', 'set', 'set', 'jell', 'set', 'congeal', 'typeset', 'set', 'set', 'set', 'countersink', 'set', 'sic', 'set', 'place', 'put', 'set', 'rig', 'set', 'set_up', 'set_up', 'lay_out', 'set', 'adjust', 'set', 'correct', 'fructify', 'set', 'dress', 'arrange', 'set', 'do', 'coif', 'coiffe', 'coiffure']\n",
            "Verbs for square: ['square', 'square_up', 'square', 'square', 'square', 'square', 'square', 'feather', 'square', 'feather', 'square']\n",
            "Verbs for lead: ['lead', 'take', 'direct', 'conduct', 'guide', 'leave', 'result', 'lead', 'lead', 'lead', 'head', 'lead', 'run', 'go', 'pass', 'lead', 'extend', 'head', 'lead', 'lead', 'top', 'contribute', 'lead', 'conduce', 'conduct', 'lead', 'direct', 'go', 'lead', 'precede', 'lead', 'run', 'lead', 'moderate', 'chair', 'lead']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "adjectives = {}\n",
        "for word in words:\n",
        "    synsets = wordnet.synsets(word)\n",
        "    adjective_synsets = [syn for syn in synsets if syn.pos() == 'a']\n",
        "\n",
        "    if adjective_synsets:\n",
        "        adjective_words = [lemma.name() for syn in adjective_synsets for lemma in syn.lemmas()]\n",
        "        adjectives[word] = adjective_words\n",
        "\n",
        "\n",
        "for word, word_adjectives in adjectives.items():\n",
        "    print(f\"Adjectives for {word}: {word_adjectives}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p9ugsljahqQ",
        "outputId": "ac01d55f-14ee-47b8-b083-54ce6d42fa61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjectives for square: ['square', 'straight', 'square']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adverbs = {}\n",
        "for word in words:\n",
        "    synsets = wordnet.synsets(word)\n",
        "    adverb_synsets = [syn for syn in synsets if syn.pos() == 'r']  # Filter only adverb synsets\n",
        "\n",
        "    if adverb_synsets:\n",
        "        adverb_words = [lemma.name() for syn in adverb_synsets for lemma in syn.lemmas()]\n",
        "        adverbs[word] = adverb_words\n",
        "\n",
        "# Print the adverbs for each word\n",
        "for word, word_adverbs in adverbs.items():\n",
        "    print(f\"Adverbs for {word}: {word_adverbs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7WKht-bblU2",
        "outputId": "8cc8c6fc-98cb-4111-ccc1-a4ada1a26bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adverbs for square: ['squarely', 'square', 'squarely', 'square', 'squarely', 'square']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "definitions = {}\n",
        "for word in words:\n",
        "    synsets = wordnet.synsets(word)\n",
        "\n",
        "    if synsets:\n",
        "        first_synset = synsets[0]\n",
        "        definition = first_synset.definition()\n",
        "        definitions[word] = definition\n",
        "\n",
        "for word, word_definition in definitions.items():\n",
        "    print(f\"Definition of {word}: {word_definition}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8tmZYfebzrJ",
        "outputId": "4f48591d-7064-4e02-8598-79b0c3164771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Definition of bear: massive plantigrade carnivorous or omnivorous mammals with long shaggy coats and strong claws\n",
            "Definition of set: a group of things of the same kind that belong together and are so used\n",
            "Definition of square: (geometry) a plane rectangle with four equal sides and four right angles; a four-sided regular polygon\n",
            "Definition of lead: an advantage held by a competitor in a race\n",
            "Definition of criteria: a basis for comparison; a reference point against which other things can be evaluated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypernyms_dict = {}\n",
        "hyponyms_dict = {}\n",
        "\n",
        "for word in words:\n",
        "    synsets = wordnet.synsets(word)\n",
        "\n",
        "    if synsets:\n",
        "        first_synset = synsets[0]\n",
        "\n",
        "        hypernyms = first_synset.hypernyms()\n",
        "        hypernyms_words = [hypernym.name() for hypernym in hypernyms]\n",
        "        hypernyms_dict[word] = hypernyms_words\n",
        "\n",
        "        hyponyms = first_synset.hyponyms()\n",
        "        hyponyms_words = [hyponym.name() for hyponym in hyponyms]\n",
        "        hyponyms_dict[word] = hyponyms_words\n",
        "\n",
        "for word in words:\n",
        "    print(f\"Word: {word}\")\n",
        "    print(f\"Hypernyms: {hypernyms_dict[word]}\")\n",
        "    print(f\"Hyponyms: {hyponyms_dict[word]}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRxc73kYef2K",
        "outputId": "5e0daff3-90c9-49ea-fed6-59ea73840b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: bear\n",
            "Hypernyms: ['carnivore.n.01']\n",
            "Hyponyms: ['american_black_bear.n.01', 'asiatic_black_bear.n.01', 'bear_cub.n.01', 'brown_bear.n.01', 'bruin.n.01', 'ice_bear.n.01', 'sloth_bear.n.01']\n",
            "\n",
            "\n",
            "Word: set\n",
            "Hypernyms: ['collection.n.01']\n",
            "Hyponyms: ['bracket.n.01', 'chess_set.n.01', 'choir.n.02', 'conjugation.n.03', 'core.n.01', 'dentition.n.02', 'field.n.12', 'field.n.13', 'field.n.15', 'intersection.n.04', 'manicure_set.n.01', 'octet.n.03', 'pair.n.01', 'portfolio.n.02', 'quartet.n.03', 'quintet.n.04', 'score.n.04', 'septet.n.03', 'sextet.n.04', 'singleton.n.02', 'suite.n.04', 'synset.n.01', 'threescore.n.01', 'trio.n.04', 'union.n.08']\n",
            "\n",
            "\n",
            "Word: square\n",
            "Hypernyms: ['rectangle.n.01', 'regular_polygon.n.01']\n",
            "Hyponyms: ['quadrate.n.02']\n",
            "\n",
            "\n",
            "Word: lead\n",
            "Hypernyms: ['advantage.n.01']\n",
            "Hyponyms: []\n",
            "\n",
            "\n",
            "Word: criteria\n",
            "Hypernyms: ['system_of_measurement.n.01']\n",
            "Hyponyms: ['baseline.n.01', 'benchmark.n.01', 'earned_run_average.n.01', 'gauge.n.02', 'grade_point_average.n.01', 'medium_of_exchange.n.01', 'norm.n.01', 'procrustean_standard.n.01', 'scale.n.01', 'yardstick.n.01']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def find_one_hyponym_pair_similarity(word):\n",
        "    synsets = wordnet.synsets(word)\n",
        "\n",
        "    if synsets:\n",
        "        first_synset = synsets[0]\n",
        "        hyponyms = first_synset.hyponyms()\n",
        "        if len(hyponyms) >= 2:\n",
        "            hyponym1, hyponym2 = hyponyms[:2]\n",
        "            similarity = hyponym1.path_similarity(hyponym2)\n",
        "            return hyponym1.name(), hyponym2.name(), similarity\n",
        "        else:\n",
        "            return f\"{word} has fewer than two hyponyms\", None, None\n",
        "\n",
        "for word in words:\n",
        "    hyponym1, hyponym2, similarity = find_one_hyponym_pair_similarity(word)\n",
        "    print(f\"Word: {word}\")\n",
        "    if hyponym1:\n",
        "        print(f\"Hyponym 1: {hyponym1}\")\n",
        "        print(f\"Hyponym 2: {hyponym2}\")\n",
        "        print(f\"Similarity: {similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa3cEVo9crrS",
        "outputId": "1ee8a6c3-64fa-4352-d50d-3f0119a2fc77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: bear\n",
            "Hyponym 1: american_black_bear.n.01\n",
            "Hyponym 2: asiatic_black_bear.n.01\n",
            "Similarity: 0.3333333333333333\n",
            "Word: set\n",
            "Hyponym 1: bracket.n.01\n",
            "Hyponym 2: chess_set.n.01\n",
            "Similarity: 0.3333333333333333\n",
            "Word: square\n",
            "Hyponym 1: square has fewer than two hyponyms\n",
            "Hyponym 2: None\n",
            "Similarity: None\n",
            "Word: lead\n",
            "Hyponym 1: lead has fewer than two hyponyms\n",
            "Hyponym 2: None\n",
            "Similarity: None\n",
            "Word: criteria\n",
            "Hyponym 1: baseline.n.01\n",
            "Hyponym 2: benchmark.n.01\n",
            "Similarity: 0.3333333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}